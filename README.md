# Ollama LLM Interceptor (Production-style)

## Prerequisites
- Python 3.10+
- Ollama running locally
  ```
  ollama run phi3
  ```

## Install deps
```
pip install httpx pydantic
```

## Run example
```
python examples/run_ollama.py
```
