# LLM Observability - Control Tower Edition

## Overview

Production-grade LLM observability system with **policy-driven enforcement**. Detects hallucinations, missing grounding, and other LLM failures, then applies configurable policies for blocking or warning.

### Key Features

- ğŸ¯ **Policy-Driven**: All enforcement decisions driven by YAML configuration
- ğŸš¨ **Failure Detection**: Detects fabricated concepts, missing grounding, domain mismatches
- âš–ï¸ **Severity Mapping**: CRITICAL â†’ BLOCK, HIGH â†’ WARN, MEDIUM/LOW â†’ LOG
- ğŸ—ï¸ **Enterprise Architecture**: Separation of detection, policy, and enforcement
- ğŸ”„ **Deterministic**: Same input = same output (no heuristics)

## Architecture

```
LLM Response â†’ Signals â†’ Control Tower â†’ Policy Engine â†’ Enforcement
                  â†“            â†“              â†“              â†“
              Detection    Evaluation    Severity       Action
                                        Mapping
```

### Control Tower vs Legacy Mode

| Aspect | Legacy (run_ollama.py) | Control Tower (run_control_tower.py) |
|--------|------------------------|---------------------------------------|
| Decision Logic | Hardcoded rules | YAML policy config |
| Severity | Heuristic-based | Policy-defined |
| Action | Verdict reduction | Direct from policy |
| Maintainability | Code changes needed | Config changes only |
| Auditability | Limited | Full policy trail |

## Prerequisites

- Python 3.10+
- Ollama running locally
  ```bash
  ollama run phi3
  ```

## Installation

```bash
# Clone repository
git clone https://github.com/pranaya-mathur/LLM-Observability.git
cd LLM-Observability

# Install dependencies
pip install -r requirements.txt
```

## Quick Start

### Control Tower Mode (Recommended)

```bash
python -m examples.run_control_tower
```

**Sample Output:**
```
[POLICY DECISION]
  Failure Class: fabricated_concept
  Severity: CRITICAL
  Action: BLOCK
  Confidence: 0.80
  Reason: Hallucinated terms/concepts pose safety risk
  Block: True

âŒ RESPONSE BLOCKED
Reason: Hallucinated terms/concepts pose safety risk
Severity: CRITICAL
```

### Legacy Mode

```bash
python -m examples.run_ollama
```

## Configuration

Edit `config/policy.yaml` to customize enforcement policies:

```yaml
failure_policies:
  fabricated_concept:
    severity: "critical"  # critical, high, medium, low
    action: "block"       # block, warn, log, allow
    reason: "Hallucinated terms/concepts pose safety risk"
  
  missing_grounding:
    severity: "high"
    action: "warn"
    reason: "Unverified claims require user awareness"
```

### Policy Modification

**No code changes needed!** Just edit YAML:

1. Change severity level â†’ Changes enforcement action automatically
2. Modify thresholds â†’ Adjusts confidence requirements
3. Add new failure classes â†’ System picks them up immediately

## Project Structure

```
LLM-Observability/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ policy.yaml          # ğŸ¯ Policy configuration (EDIT THIS)
â”‚   â””â”€â”€ policy_loader.py     # YAML loader
â”œâ”€â”€ contracts/
â”‚   â”œâ”€â”€ failure_classes.py   # Failure taxonomy
â”‚   â””â”€â”€ severity_levels.py   # Severity & action enums
â”œâ”€â”€ enforcement/
â”‚   â””â”€â”€ control_tower.py     # Policy-driven enforcement
â”œâ”€â”€ signals/
â”‚   â””â”€â”€ runner.py            # Signal detection
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ run_control_tower.py # ğŸ†• New policy-driven example
â”‚   â””â”€â”€ run_ollama.py        # Legacy example
â””â”€â”€ core/
    â””â”€â”€ interceptor.py       # LLM call interceptor
```

## Example Use Cases

### 1. Block Hallucinations

**Scenario**: LLM invents "RAG = Ruthenium-Arsenic Growth"

**Policy**:
```yaml
fabricated_concept:
  severity: "critical"
  action: "block"
```

**Result**: Response blocked entirely âŒ

### 2. Warn on Missing Sources

**Scenario**: LLM makes claims without citations

**Policy**:
```yaml
missing_grounding:
  severity: "high"
  action: "warn"
```

**Result**: Response delivered with warning âš ï¸

### 3. Log Tone Issues

**Scenario**: Response is too casual

**Policy**:
```yaml
tone_issue:
  severity: "low"
  action: "log"
```

**Result**: Response allowed, logged for analysis â„¹ï¸

## Production Readiness

### âœ… What's Production-Ready

- Policy-driven architecture
- Type-safe enums and contracts
- Separation of concerns
- Configuration-based enforcement
- Deterministic decisions

### ğŸš§ What Needs Work

- [ ] Structured logging (replace print statements)
- [ ] Metrics collection and monitoring
- [ ] Database persistence for audit trail
- [ ] Advanced signal detection (current signals are basic)
- [ ] API wrapper for easy integration

## Contributing

To add new failure classes:

1. Add to `contracts/failure_classes.py`
2. Add signal detector in `signals/`
3. Configure policy in `config/policy.yaml`

No changes needed in enforcement logic!

## License

MIT License

## Acknowledgments

Built with production MLOps principles for enterprise LLM governance.
